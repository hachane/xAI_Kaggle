{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8690955,"sourceType":"datasetVersion","datasetId":5211395},{"sourceId":8824214,"sourceType":"datasetVersion","datasetId":5307762},{"sourceId":8856375,"sourceType":"datasetVersion","datasetId":5327889},{"sourceId":8859143,"sourceType":"datasetVersion","datasetId":5315486}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Imports","metadata":{}},{"cell_type":"markdown","source":"## Phase 1","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport os\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, HTML\n!pip install watermark --quiet\nimport random\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay,\n    accuracy_score,\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:39:48.191447Z","iopub.execute_input":"2024-07-04T15:39:48.191864Z","iopub.status.idle":"2024-07-04T15:39:55.171090Z","shell.execute_reply.started":"2024-07-04T15:39:48.191826Z","shell.execute_reply":"2024-07-04T15:39:55.170068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_dir = '/kaggle/input'\n\n# # List all directories and files in the input directory\n# all_files = os.listdir(input_dir)\n\n# # Filter to get only directories\n# all_dirs = [f for f in all_files if os.path.isdir(os.path.join(input_dir, f))]\n\n# print(\"Directories in input:\")\n# for directory in all_dirs:\n#     print(directory)\n\n# # Walk through all directories and files in the input directory\n# for root, dirs, files in os.walk(input_dir):\n#     for file in files:\n#         print(os.path.join(root, file))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:25.018005Z","iopub.execute_input":"2024-07-04T10:57:25.018350Z","iopub.status.idle":"2024-07-04T10:57:25.022211Z","shell.execute_reply.started":"2024-07-04T10:57:25.018313Z","shell.execute_reply":"2024-07-04T10:57:25.021342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_name = 'tcga-brca-gexcna'\nCOHORT = 'tcga-brca-GExCNA-2000x2000-MinMaxScaler'\ntmp = f'/kaggle/input/{dataset_name}'\n# %cd {tmp}\n\n# from models import init_model_dict\n# from utils import load_model_dict\n# from train_test import prepare_trte_data, gen_trte_adj_mat, test_epoch\n\n# from train_test import train_test\n# from train_test import gen_trte_adj_mat\n# from utils import save_model_dict\n\n# %cd '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:41:24.948701Z","iopub.execute_input":"2024-07-04T15:41:24.949083Z","iopub.status.idle":"2024-07-04T15:41:24.953860Z","shell.execute_reply.started":"2024-07-04T15:41:24.949038Z","shell.execute_reply":"2024-07-04T15:41:24.952828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd '/kaggle/input/brca-deepssc'\n\nfrom utils import load_model_dict\n\n# %cd '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:41:28.642819Z","iopub.execute_input":"2024-07-04T15:41:28.643205Z","iopub.status.idle":"2024-07-04T15:41:28.720606Z","shell.execute_reply.started":"2024-07-04T15:41:28.643167Z","shell.execute_reply":"2024-07-04T15:41:28.719724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phase 2","metadata":{}},{"cell_type":"code","source":"from scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:25.052275Z","iopub.execute_input":"2024-07-04T10:57:25.052606Z","iopub.status.idle":"2024-07-04T10:57:31.974821Z","shell.execute_reply.started":"2024-07-04T10:57:25.052566Z","shell.execute_reply":"2024-07-04T10:57:31.973709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phase 3","metadata":{}},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:31.976575Z","iopub.execute_input":"2024-07-04T10:57:31.976970Z","iopub.status.idle":"2024-07-04T10:57:31.983704Z","shell.execute_reply.started":"2024-07-04T10:57:31.976922Z","shell.execute_reply":"2024-07-04T10:57:31.982809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.0. Hyperparameters","metadata":{}},{"cell_type":"code","source":"cuda = True if torch.cuda.is_available() else False\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'cuda: {cuda}')\n%load_ext watermark\n%watermark -a 'Le Hoang' -u -d -v -p torch,numpy","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:31.984970Z","iopub.execute_input":"2024-07-04T10:57:31.985314Z","iopub.status.idle":"2024-07-04T10:57:32.009895Z","shell.execute_reply.started":"2024-07-04T10:57:31.985281Z","shell.execute_reply":"2024-07-04T10:57:32.008796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed: int = 42) -> None:\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    print(f\"Random seed set as {seed}\")\n\nrseed = 42\nset_seed(rseed)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.012938Z","iopub.execute_input":"2024-07-04T10:57:32.013295Z","iopub.status.idle":"2024-07-04T10:57:32.019850Z","shell.execute_reply.started":"2024-07-04T10:57:32.013267Z","shell.execute_reply":"2024-07-04T10:57:32.018924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !conda list -e > /kaggle/working/conda_requirements.txt\n# !pip freeze -l > /kaggle/working/pip_requirements.txt ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.021959Z","iopub.execute_input":"2024-07-04T10:57:32.022347Z","iopub.status.idle":"2024-07-04T10:57:32.030656Z","shell.execute_reply.started":"2024-07-04T10:57:32.022300Z","shell.execute_reply":"2024-07-04T10:57:32.029781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"postfix_tr = '_tr'\npostfix_te = '_val'\n\ndata_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\nmain_deepssc = '/kaggle/input/brca-deepscc/main.py'\nmodel_folder = '/kaggle/working/models'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.031715Z","iopub.execute_input":"2024-07-04T10:57:32.031962Z","iopub.status.idle":"2024-07-04T10:57:32.041716Z","shell.execute_reply.started":"2024-07-04T10:57:32.031939Z","shell.execute_reply":"2024-07-04T10:57:32.040859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lr_methAE = 1e-4\n# n_epoch_methAE = 40\n# lr_geAE = 1e-4\n# n_epoch_geAE = 40\n# lr_cnaAE = 1e-4\n# n_epoch_cnaAE = 40\n# lr_AE = 1e-6\n# lr_clf = 1e-5\n# patience = 20\n# batch_size = 16\n# wd_AE = 0.0\n\n# if 'BRCA' in data_folder:\n#     wd_clf = 5e-1\n# else:\n#     wd_clf = 1e-3","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.042982Z","iopub.execute_input":"2024-07-04T10:57:32.043362Z","iopub.status.idle":"2024-07-04T10:57:32.051766Z","shell.execute_reply.started":"2024-07-04T10:57:32.043326Z","shell.execute_reply":"2024-07-04T10:57:32.051071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'lr_methAE': 2, 'n_epoch_methAE': 5, 'lr_geAE': 66, 'n_epoch_geAE': 5, \n# 'lr_cnaAE': 89, 'n_epoch_cnaAE': 1, 'lr_AE': 58, 'patience': 12, 'wd_AE': 3\n\nlr_methAE = 2e-5\nn_epoch_methAE = 100\nlr_geAE = 66e-5\nn_epoch_geAE = 100\nlr_cnaAE = 89e-5\nn_epoch_cnaAE = 20\nlr_AE = 58e-6\nlr_clf = 1e-5\npatience = 120\nbatch_size = 16\nwd_AE = 3e-5\nwd_clf = 1e-3","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.052784Z","iopub.execute_input":"2024-07-04T10:57:32.053063Z","iopub.status.idle":"2024-07-04T10:57:32.062491Z","shell.execute_reply.started":"2024-07-04T10:57:32.053011Z","shell.execute_reply":"2024-07-04T10:57:32.061585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\n# model_folder = '/kaggle/working/models'\n# train_file = f'/kaggle/input/{dataset_name}/main_mogonet.py'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.063518Z","iopub.execute_input":"2024-07-04T10:57:32.063798Z","iopub.status.idle":"2024-07-04T10:57:32.072840Z","shell.execute_reply.started":"2024-07-04T10:57:32.063772Z","shell.execute_reply":"2024-07-04T10:57:32.072115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Subtypes\nloc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    # dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\nLABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.073956Z","iopub.execute_input":"2024-07-04T10:57:32.074262Z","iopub.status.idle":"2024-07-04T10:57:32.087549Z","shell.execute_reply.started":"2024-07-04T10:57:32.074231Z","shell.execute_reply":"2024-07-04T10:57:32.086839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Config\n\nnum_models=5\nidx_list = list(range(1,num_models+1))\nview_list = [1,2]\nretrain=True\nRun_MOGONET = False","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.088509Z","iopub.execute_input":"2024-07-04T10:57:32.088786Z","iopub.status.idle":"2024-07-04T10:57:32.098193Z","shell.execute_reply.started":"2024-07-04T10:57:32.088760Z","shell.execute_reply":"2024-07-04T10:57:32.097472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Check data size\n# for fold_id in [3]:\n# #     print(f'idx data: {fold_id}')\n#     tmp = list(LABEL_MAPPING_NAME)\n#     label_files = ['tr', 'te', 'val']\n#     dict = {\n#         'tr': 'Train set',\n#         'te': 'Test set',\n#         'val': 'Validation set'\n#     }\n    \n    \n#     for label_file in label_files:\n# #         print(dict[label_file])\n#         df = pd.read_csv(f'{data_folder}/{fold_id}/labels_{label_file}.csv', header=None, names=['featname'])\n#         feature_counts = df['featname'].value_counts().sort_index()\n        \n#         print(f'{dict[label_file]}')\n                \n#         # Create an HTML table for the feature counts\n#         html_table = '<table><tr><th>Label</th><th>Count</th></tr>'\n#         for feature, count in feature_counts.items():\n#             html_table += f'<tr><td>{tmp[feature]}</td><td>{count}</td></tr>'\n#         html_table += '</table>'\n\n#         # Display the HTML table\n#         display(HTML(html_table))\n# #     print('\\n', '*'*100)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.099245Z","iopub.execute_input":"2024-07-04T10:57:32.099522Z","iopub.status.idle":"2024-07-04T10:57:32.109021Z","shell.execute_reply.started":"2024-07-04T10:57:32.099485Z","shell.execute_reply":"2024-07-04T10:57:32.108234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_view = len(view_list)\nnum_class = len(LABEL_MAPPING_NAME)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.110142Z","iopub.execute_input":"2024-07-04T10:57:32.110425Z","iopub.status.idle":"2024-07-04T10:57:32.118733Z","shell.execute_reply.started":"2024-07-04T10:57:32.110398Z","shell.execute_reply":"2024-07-04T10:57:32.118006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"added_softmax = False\n\n# Prepairing raw data\ndef preprocessing_data(tup_tensor_test_data, data_folder):\n    data_tr_list = []\n    data_te_list = []\n#     print(view_list)\n\n    for i in view_list:\n        data_tr_list.append(torch.tensor(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','),dtype=torch.float32))\n        data_te_list.append(tup_tensor_test_data[i-1])\n        if cuda:\n            data_tr_list[i-1] = data_tr_list[i-1].to(device)\n            data_te_list[i-1] = data_te_list[i-1].to(device)       \n\n    # num train's records, test's records\n    num_tr = data_tr_list[0].shape[0]\n    num_te = data_te_list[0].shape[0]\n\n    # idx\n    trte_idx = {}\n    trte_idx[\"tr\"] = list(range(num_tr))\n    trte_idx[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n\n    # num of views or num of omics\n    num_view = len(view_list)\n    data_tensor_list = []\n    for i in range(num_view):\n        data_tensor_list.append(torch.cat((data_tr_list[i], data_te_list[i]), axis=0))\n        if cuda:\n            data_tensor_list[i] = data_tensor_list[i].to(device)#cuda()\n    \n    data_train_list = []\n    data_trte_list = []\n    for i in range(len(data_tensor_list)):\n        data_train_list.append(data_tensor_list[i][trte_idx[\"tr\"]].clone())\n\n        tup_seq_data = (data_tensor_list[i][trte_idx[\"tr\"]].clone(), data_tensor_list[i][trte_idx[\"te\"]].clone())\n        data_trte_list.append(\n            torch.cat(tup_seq_data,axis=0)\n        )\n    return data_train_list, data_trte_list,trte_idx\n\n\n# III. For Feature Important\n\ndef custom_logit_predictor(*tup_tensor_data, data_folder):\n    global added_softmax\n    added_softmax = True\n    \n    model = model_dict\n    model.to(device)\n    model.eval()\n        \n    tup_tensor_data = tuple(tensor_data.to(device) if cuda else tensor_data for tensor_data in tup_tensor_data)\n    data_tr_list, data_trte_list, trte_idx = preprocessing_data(tup_tensor_data, data_folder)\n    \n    num_view = len(view_list)\n    if num_view == 2:\n#         meth_repr = model.meth_repr(data_trte_list[0])\n        ge_repr = model.ge_repr(data_trte_list[0])\n        cna_repr = model.cna_repr(data_trte_list[1])\n        combined_repr = torch.hstack((ge_repr, cna_repr))\n        c = model.classifier(combined_repr)\n    else:\n        raise ValueError(\"The number of views should be exactly 2.\")\n    \n    c = c[trte_idx[\"te\"], :]\n\n    if added_softmax:\n        c = F.softmax(c, dim=1)\n    \n    return c","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.119929Z","iopub.execute_input":"2024-07-04T10:57:32.120193Z","iopub.status.idle":"2024-07-04T10:57:32.137067Z","shell.execute_reply.started":"2024-07-04T10:57:32.120169Z","shell.execute_reply":"2024-07-04T10:57:32.136296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dict={}\ndef load_model(data_folder, model_folder):\n    global model_dict\n    model_dict = load_model_dict(data_folder, model_folder, batch_size)\n\n# def load_model(data_folder, model_folder):\n#     global model_dict\n\n#     # Debug print to check the type and value of model_dict\n#     print(f\"model_dict before loading: {model_dict} (type: {type(model_dict)})\")\n\n#     # Ensure model_dict is a dictionary\n#     if not isinstance(model_dict, dict):\n#         raise TypeError(f\"Expected model_dict to be a dictionary, got {type(model_dict)}\")\n\n#     # Ensure all keys in model_dict are strings\n#     for key in model_dict:\n#         if not isinstance(key, str):\n#             raise TypeError(f\"Expected string key in model_dict, got {type(key)} with value {key}\")\n\n#     model_dict = load_model_dict(model_folder, model_dict, batch_size)\n\n#     return model_dict","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.138138Z","iopub.execute_input":"2024-07-04T10:57:32.138409Z","iopub.status.idle":"2024-07-04T10:57:32.151142Z","shell.execute_reply.started":"2024-07-04T10:57:32.138382Z","shell.execute_reply":"2024-07-04T10:57:32.150135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_classification_report(\n    n_class,\n    label,\n    pred,\n    label_mapping_name,\n    cmap=\"Blues\",\n    fmt=\".2%\",\n    annot=True,\n    path=None,  # str path to save fig. If not None\n    shown=True,\n):\n\n    clf_report = classification_report(\n        label,\n        pred,\n        target_names=label_mapping_name,\n        digits=4,\n        zero_division=0,\n        output_dict=True,\n    )\n\n    clf_df = pd.DataFrame(clf_report)\n    clf_df.loc[[\"precision\", \"recall\"], \"accuracy\"] = np.nan\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    fig.set_figwidth(12)\n    ConfusionMatrixDisplay(\n        confusion_matrix(label, pred), display_labels=label_mapping_name\n    ).plot(cmap=cmap, ax=ax1)\n    sns.heatmap(\n        clf_df.iloc[:-1, :].T, annot=annot, cmap=cmap, robust=True, ax=ax2, fmt=fmt\n    )\n    if path is not None:\n        fig.savefig(path, dpi=300)\n    if shown:\n        plt.show()\n    else:\n        plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:04:32.486382Z","iopub.execute_input":"2024-07-04T16:04:32.486763Z","iopub.status.idle":"2024-07-04T16:04:32.496813Z","shell.execute_reply.started":"2024-07-04T16:04:32.486727Z","shell.execute_reply":"2024-07-04T16:04:32.495918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.1. TRAINING","metadata":{}},{"cell_type":"code","source":"# if retrain:\n#     model_folder = '/kaggle/working/models'\n#     for fold_id in idx_list:\n#         print(f'idx data: {fold_id}')\n\n#         data_folder_idx = data_folder + f'/{fold_id}'\n#         model_folder_idx = model_folder + f'/{fold_id}'\n\n#         if not bool_using_early_stopping:\n#             patience=None\n        \n        \n#         !python '{train_file}' '{rseed}' '{data_folder_idx}' '{postfix_tr}' '{postfix_te}' '{model_folder_idx}' '{view_list}' '{num_epoch_pretrain}' '{num_epoch}' '{lr_e_pretrain}' '{lr_e}' '{lr_c}' '{bool_using_early_stopping}' '{verbose}' '{print_hyper}' '{dim_he_list}' '{patience}'\n\n#         print('*'*100)\n# else:\n#     model_folder = f'/kaggle/input/{dataset_name}/models'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.166009Z","iopub.execute_input":"2024-07-04T10:57:32.166382Z","iopub.status.idle":"2024-07-04T10:57:32.174771Z","shell.execute_reply.started":"2024-07-04T10:57:32.166347Z","shell.execute_reply":"2024-07-04T10:57:32.173909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.175937Z","iopub.execute_input":"2024-07-04T10:57:32.176314Z","iopub.status.idle":"2024-07-04T10:57:32.189440Z","shell.execute_reply.started":"2024-07-04T10:57:32.176274Z","shell.execute_reply":"2024-07-04T10:57:32.188584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if retrain:\n    data_folder = f'/kaggle/input/{dataset_name}/{COHORT}'\n    main_deepssc = '/kaggle/input/brca-deepssc/main.py'\n    model_folder = '/kaggle/working/models'\n    idx_list = list(range(1,6))\n    for fold_id in idx_list:\n        print(f'idx data: {fold_id}')\n\n        data_dir_deepssc_idx = data_folder + f'/{fold_id}'\n        result_dir_deepssc_idx = model_folder + f'/{fold_id}'\n\n        # Kiểm tra nếu tệp tồn tại\n        if not os.path.exists(main_deepssc):\n            print(f\"Error: The file '{main_deepssc}' does not exist.\")\n            continue\n\n        !python '{main_deepssc}' '{data_dir_deepssc_idx}' '{result_dir_deepssc_idx}' '{rseed}' \\\n            '{lr_methAE}' '{n_epoch_methAE}' '{lr_geAE}' '{n_epoch_geAE}' '{lr_cnaAE}' '{n_epoch_cnaAE}' \\\n            '{lr_AE}' '{lr_clf}' '{patience}' '{batch_size}' '{wd_AE}' '{wd_clf}'\n\n        print('*'*100)\nelse :\n    model_folder = f'/kaggle/input/brca-deepscc/models'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:57:32.193324Z","iopub.execute_input":"2024-07-04T10:57:32.193576Z","iopub.status.idle":"2024-07-04T11:02:07.035387Z","shell.execute_reply.started":"2024-07-04T10:57:32.193552Z","shell.execute_reply":"2024-07-04T11:02:07.034274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1.2. Load trained models and check accuracy phase 1","metadata":{}},{"cell_type":"code","source":"view_list = [1,2]\ndef evaluate_model(bool_report = True, _type_data='te'):\n    # Accumulate ground truth and predictions\n    all_labels = []\n    all_preds = []\n\n    for idx in idx_list:\n        cur_model_folder = f'{model_folder}/{idx}'\n        cur_data_folder = f\"{data_folder}/{idx}/\"\n        load_model(cur_data_folder, cur_model_folder)\n    #     print(cur_model_folder)\n\n        _data_list=[]\n\n        _label = labels_te = np.loadtxt(os.path.join(cur_data_folder, f\"labels_{_type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(cur_data_folder, f\"{i}_{_type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        _tensor_data_list = tuple(torch.tensor(np_arr, dtype=torch.float32).to(device) for np_arr in _data_list)\n        pred = custom_logit_predictor(*_tensor_data_list, data_folder=cur_data_folder)\n\n        pred = np.array(torch.argmax(pred.cpu(), dim=1))\n\n        all_labels.extend(_label)\n        all_preds.extend(pred)\n\n    # Convert lists to numpy arrays\n    all_labels = np.array(all_labels)\n    all_preds = np.array(all_preds)\n    \n    if bool_report:\n        if not os.path.exists(\"/kaggle/working/phase1\"):\n            os.makedirs(\"/kaggle/working/phase1\")\n        display_classification_report(\n            num_class,\n            all_labels,\n            all_preds,\n            LABEL_MAPPING_NAME,\n            path=f\"/kaggle/working/phase1/Evaluate_model_{_type_data}\",\n        )\n    \n    return accuracy_score(all_labels, all_preds)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:02:07.037997Z","iopub.execute_input":"2024-07-04T11:02:07.038351Z","iopub.status.idle":"2024-07-04T11:02:07.049234Z","shell.execute_reply.started":"2024-07-04T11:02:07.038309Z","shell.execute_reply":"2024-07-04T11:02:07.048307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(_type_data='tr')\nevaluate_model(_type_data='val')\nevaluate_model(_type_data='te')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:02:07.050513Z","iopub.execute_input":"2024-07-04T11:02:07.051056Z","iopub.status.idle":"2024-07-04T11:03:23.747979Z","shell.execute_reply.started":"2024-07-04T11:02:07.051001Z","shell.execute_reply":"2024-07-04T11:03:23.746848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODULE 2: Integrated Gradient","metadata":{}},{"cell_type":"code","source":"biomarkers_folder = '/kaggle/working/biomarkers/' + COHORT\npostfix_tr = '_tr'\npostfix_te = '_val'","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:23.749428Z","iopub.execute_input":"2024-07-04T11:03:23.749808Z","iopub.status.idle":"2024-07-04T11:03:23.763453Z","shell.execute_reply.started":"2024-07-04T11:03:23.749769Z","shell.execute_reply":"2024-07-04T11:03:23.760078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.1. Baselines for IG","metadata":{}},{"cell_type":"code","source":"# Load dict mapping name of {int_id_label:label_name} that int_id_label start from 0 and {int_id_omic:omic_name} that int_id_omic start from 1\nloc_file_json_id_label = data_folder + '/1/dct_index_subtype.json'\nloc_file_json_id_omic = data_folder + '/1/dict_id_omics.json'\n\nwith open(loc_file_json_id_label) as file_json_id_label:\n    dct_LABEL_MAPPING_NAME = json.load(file_json_id_label)\n    dct_LABEL_MAPPING_NAME = {int(k): v for k,v in dct_LABEL_MAPPING_NAME.items()} # convert str number key to int\n# print(\"\\n{int_id_label:label_name} = \", dct_LABEL_MAPPING_NAME)\n\nwith open(loc_file_json_id_omic) as file_json_id_omic:\n    dct_OMIC_MAPPING_NAME = json.load(file_json_id_omic)\n    dct_OMIC_MAPPING_NAME = {int(k): v for k,v in dct_OMIC_MAPPING_NAME.items()} # convert str number key to int\n# print(\"\\n{int_id_omic:omic_name} = \", dct_OMIC_MAPPING_NAME)\n\n\n\n###############\n\n# may be fixed\nn_folds = num_models # fold id start from 1\ntype_data = 'tr' # fixed\nfold_start_id = 1\nlist_fold_id = list(range(n_folds+fold_start_id)[fold_start_id:])\n\n\ndict_fold_dict_baseline = {}\n\nfor fold_id in list_fold_id:\n    data_folder_idx = data_folder + f'/{fold_id}'\n#     print(f'\\n*Using data of fold_id= \"{fold_id}\" with data type = \"{type_data}\" for each omic (total \"{len(dct_OMIC_MAPPING_NAME)}\" type(s) of omic) in folder \"{data_folder_idx}\" to create baseline')\n    ##############\n    tmp_label = pd.read_csv(os.path.join(data_folder_idx, f'labels_{type_data}.csv'), header=None)\n\n    tmp_dict_omic_pd_data = {id_omic: pd.read_csv(os.path.join(data_folder_idx, f'{str(id_omic)}_{type_data}.csv'), header=None) for id_omic in dct_OMIC_MAPPING_NAME.keys()}\n    tmp_dict_omic_shape = {id_omic: tmp_dict_omic_pd_data[id_omic].shape[1] for id_omic in dct_OMIC_MAPPING_NAME.keys()} # number of features each omic\n    \n    tmp_dict_omic_pd_data_w_label = {id_omic: tmp_dict_omic_pd_data[id_omic].copy(deep=True) for id_omic in dct_OMIC_MAPPING_NAME.keys()}\n    for id_omic in tmp_dict_omic_pd_data_w_label.keys():\n        tmp_dict_omic_pd_data_w_label[id_omic]['subtype'] = tmp_label[0]\n\n    tmp_dict_baseline= {}\n    \n    #############################\n    tmp_dict_baseline['zeros']= tuple(torch.zeros((1,tmp_dict_omic_shape[id_omic])\n                                              , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    tmp_dict_baseline['micro_means']= tuple(torch.tensor(tmp_dict_omic_pd_data[id_omic].mean(axis=0).values.reshape(1,-1)\n                                                         , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    tmp_dict_baseline['macro_means']= tuple(torch.tensor(tmp_dict_omic_pd_data_w_label[id_omic].groupby('subtype').mean().mean(axis=0).values.reshape(1,-1)\n                                                         , dtype=torch.float32) for id_omic in dct_OMIC_MAPPING_NAME.keys())\n    ##########################################################\n\n    tmp_dict_baseline['dict_default_micro_means']= {}\n    \n    tmp_list_of_list_exclude_cursor_label_id = [sorted(list(set(dct_LABEL_MAPPING_NAME.keys()) - set([label_id]))) for label_id in dct_LABEL_MAPPING_NAME.keys()]\n    tmp_dict_baseline['dict_default_macro_means']= {}\n    \n    for label_id in dct_LABEL_MAPPING_NAME.keys():\n        tmp_dict_baseline['dict_default_macro_means'][label_id] = tuple(\n            torch.tensor(\n                tmp_dict_omic_pd_data_w_label[id_omic].groupby('subtype').mean().loc[tmp_list_of_list_exclude_cursor_label_id[label_id]].mean(axis=0).values.reshape(1,-1)\n                ,dtype=torch.float32\n            ) for id_omic in dct_OMIC_MAPPING_NAME.keys()\n        )\n        \n        tmp_dict_baseline['dict_default_micro_means'][label_id] = tuple(\n            torch.tensor(\n                tmp_dict_omic_pd_data_w_label[id_omic][\n                    tmp_dict_omic_pd_data_w_label[id_omic]['subtype'] != label_id # filter to exclude row have label is {label_id}\n                ].loc[:,tmp_dict_omic_pd_data_w_label[id_omic].columns != 'subtype' # then filter to exclude column of label before cal mean for all columns\n                     ].mean(axis=0).values.reshape(1,-1)\n                ,dtype=torch.float32\n            ) for id_omic in dct_OMIC_MAPPING_NAME.keys()\n        )\n    ##########################################################\n     \n    # Final assign\n    dict_fold_dict_baseline[fold_id] = tmp_dict_baseline\n    \n    print(f'For fold_id = \"{fold_id}\" Done create all baseline type/with name:\\n\\tin {list(tmp_dict_baseline.keys())}')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:23.765167Z","iopub.execute_input":"2024-07-04T11:03:23.765555Z","iopub.status.idle":"2024-07-04T11:03:28.939017Z","shell.execute_reply.started":"2024-07-04T11:03:23.765503Z","shell.execute_reply":"2024-07-04T11:03:28.938105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_attribution_scores_for_folder(input, _label, cur_data_folder, idx_model, type_base_line, _n_steps=100):\n    \n    # Initialize Integrated Gradients with the custom model predictor\n    ig = IntegratedGradients(lambda *inputs: custom_logit_predictor(*inputs, data_folder=cur_data_folder))\n    \n    number_of_samples = len(_label)\n    \n    # Calculate attribute scores by batch data to avoid running out of memory\n    # 200 is the maximum (approximate) number of samples that will not cause run out of memory with this TCGA BRCA data (on Train data)\n    max_samples_per_batch = 100\n    # Get list end of index to split data into batches\n    list_end_index = [max_samples_per_batch*times \n                      for times in range(1,int(np.ceil(number_of_samples/max_samples_per_batch)))\n                     ] + [number_of_samples]\n    \n    attr = {}\n    for subtype_idx, subtype in enumerate(LABEL_MAPPING_NAME):\n        #----------------------------------------\n        start = 0\n#             print(f'\\n\\t\\t<> Calculate attribution scores with subtype: \"{subtype}\":')\n\n\n        if type_base_line[:4] == 'dict':\n#                 print(f'\\t\\t Type baseline:\\n\\t\\t  [{type_base_line}] -> Special baseline for each subtype')\n            baseline = dict_fold_dict_baseline[idx_model][type_base_line][subtype_idx]\n        else:\n#                 print(f'\\t\\t Type baseline:\\n\\t\\t  [{type_base_line}]')\n            baseline = dict_fold_dict_baseline[idx_model][type_base_line]\n        if cuda:\n            baseline = tuple(tensor_i.cuda() for tensor_i in baseline)\n#             print(f'\\t\\t Model pred score:\\n\\t\\t  {custom_logit_predictor(*baseline, data_folder=cur_data_folder).detach().cpu().numpy()} -> SUM={torch.sum(custom_logit_predictor(*baseline, data_folder=cur_data_folder)).detach().cpu().numpy()}')\n\n        for end in list_end_index:\n#                 print(f'\\t\\t\\t:samples from iloc {start} to {end}:')\n\n            input_tensor = tuple(input_omic[start:end].requires_grad_() for input_omic in input)\n\n            attr_temp, delta_temp = ig.attribute(input_tensor,\n                                                 baselines=baseline,\n                                                 target= subtype_idx, return_convergence_delta=True,\n                                                n_steps=_n_steps)\n            # concatenate genes attribute score for multi-omics data\n            attr_temp = np.concatenate(tuple(attr_temp[idx_atr].detach().cpu().numpy() for idx_atr in range(len(attr_temp))), axis=1)\n            if start == 0:\n                attr[subtype] =  attr_temp\n            else:\n                attr[subtype] = np.concatenate((attr[subtype],attr_temp),axis=0)\n            start=end\n#             print(f'\\t\\t\\t: [Delta temp: min={delta_temp.min()}, max={delta_temp.max()}, mean={delta_temp.mean()}, std={delta_temp.std()}]\\n')\n\n    return attr","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:28.940282Z","iopub.execute_input":"2024-07-04T11:03:28.940577Z","iopub.status.idle":"2024-07-04T11:03:28.951744Z","shell.execute_reply.started":"2024-07-04T11:03:28.940547Z","shell.execute_reply":"2024-07-04T11:03:28.950677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.2. Calculate and Sort IG's score of each feature from: train data + trained model","metadata":{}},{"cell_type":"code","source":"topn=10","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:28.952844Z","iopub.execute_input":"2024-07-04T11:03:28.953136Z","iopub.status.idle":"2024-07-04T11:03:28.972295Z","shell.execute_reply.started":"2024-07-04T11:03:28.953104Z","shell.execute_reply":"2024-07-04T11:03:28.971448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cal_feat_imp(num_models, type_base_line ='zeros',_n_steps=100, type_data='tr'):\n    \n    loc_file_json_id_omic = data_folder + '/1/dct_index_subtype.json'\n    with open(loc_file_json_id_omic) as file_json_id_omic:\n        dct_LABEL_MAPPING_NAME = json.load(file_json_id_omic)\n    LABEL_MAPPING_NAME = dct_LABEL_MAPPING_NAME.values() \n    \n    dct_feat_imp_by_models = {}\n    for idx_model in range(1,num_models+1):\n        data_folder_idx = data_folder + f'/{idx_model}'\n        model_folder_idx = model_folder + f'/{idx_model}'\n        added_softmax = True\n        \n        # loading dataset\n        _data_list=[]\n        _label = np.loadtxt(os.path.join(data_folder_idx, f\"labels_{type_data}.csv\"), delimiter=',').astype(int)\n\n        for i in view_list:\n            _data_loc = os.path.join(data_folder_idx, str(i)+ f\"_{type_data}.csv\")\n            _data_list.append(np.loadtxt(_data_loc, delimiter=','))\n        _tensor_data_list = tuple(torch.tensor(np_arr,dtype=torch.float32).to(device) for np_arr in _data_list)\n\n        gene_name = []\n        for v in view_list:\n            df = pd.read_csv(os.path.join(data_folder_idx, str(v)+\"_featname.csv\"), header=None)    \n            gene_name.extend(df[0].values.tolist())\n            # DONE USE THIS: gene_name.extend(df[0].str.split(r'\\|').str[0].values.tolist()) # only used when want combined same features that first part before | symbol if exist\n\n        \n        ## load models weights\n        load_model(data_folder_idx, model_folder_idx)\n        \n        #---------------------------------------------------------------------\n        start_time=datetime.now()\n\n        # Calculate attribute score:\n        attr = calculate_attribution_scores_for_folder(_tensor_data_list, _label, data_folder_idx, idx_model, type_base_line, _n_steps)\n        \n        # ------------------------------\n        lst_ordered_subtype = list(attr.keys())\n        stack_subtype_attr = np.stack(tuple(attr[subtype] for subtype in lst_ordered_subtype))\n        feat_imp_like_each_class = np.abs(stack_subtype_attr).mean(axis=1)\n        feat_imp_like = feat_imp_like_each_class.sum(axis=0)\n        \n        dct_feat_imp_by_models[idx_model] = feat_imp_like\n    \n    # along models\n    final_feat_imp_like = np.mean(list(dct_feat_imp_by_models.values()), axis=0)\n\n    idx_sorted_desc_mean_abs_sum = np.argsort(final_feat_imp_like)[::-1] # Note hien tai dang khong quan tam examples nao dung, example nao du doan sai nhu mot so cach o duoi day\n    sorted_score_feat_imp_like = final_feat_imp_like[idx_sorted_desc_mean_abs_sum]\n    rank_imp_feats_by_abs_mean_sum_without_combine_same_gene_name = list(np.array(gene_name)[idx_sorted_desc_mean_abs_sum])\n    pd_rank_by_abs_mean_sum = pd.DataFrame({'gene_name': rank_imp_feats_by_abs_mean_sum_without_combine_same_gene_name}) #, 'score':sorted_score_feat_imp_like\n    print(f'\\t=>Result (Here print out the top {topn} biomakers with highest values):')\n    end_time=datetime.now()\n    print(f'\\tRun in {end_time-start_time}')\n    display(pd_rank_by_abs_mean_sum.head(topn))\n    return pd_rank_by_abs_mean_sum","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:28.973461Z","iopub.execute_input":"2024-07-04T11:03:28.973715Z","iopub.status.idle":"2024-07-04T11:03:28.988367Z","shell.execute_reply.started":"2024-07-04T11:03:28.973691Z","shell.execute_reply":"2024-07-04T11:03:28.987498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def export_biomarker_file(list_concerned_type_baseline, list_concerned_type_data, list_concerned_num_models, biomarkers_folder, _n_steps=100):\n    list_biomakers_file_loc = []\n    print('_'*100)\n    print(f'Biomarker Discovery for {biomarkers_folder.split(\"/\")[-1]} cohort:')\n    pd_results = {}\n    for type_base_line in list_concerned_type_baseline:\n        pd_results[type_base_line] = {}\n        for type_data in list_concerned_type_data:\n            pd_results[type_base_line][type_data] = {}\n            for num_models in list_concerned_num_models:\n                \n                pd_results[type_base_line][type_data][num_models] = cal_feat_imp(num_models=num_models,type_base_line=type_base_line,_n_steps=n_steps, type_data= type_data)\n\n                if not os.path.exists(biomarkers_folder):\n                    os.makedirs(biomarkers_folder)\n                    \n                biomakers_file_loc = biomarkers_folder + f'/IG_{type_base_line}_{type_data}_{num_models}_{data_folder.split(\"/\")[-1]}.csv'\n                pd_results[type_base_line][type_data][num_models][['gene_name']].to_csv(biomakers_file_loc, index=False)\n                list_biomakers_file_loc.append(biomakers_file_loc)\n\n    print()\n    return list_biomakers_file_loc","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:28.989564Z","iopub.execute_input":"2024-07-04T11:03:28.989894Z","iopub.status.idle":"2024-07-04T11:03:29.002913Z","shell.execute_reply.started":"2024-07-04T11:03:28.989866Z","shell.execute_reply":"2024-07-04T11:03:29.002115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_concerned_type_baseline = ['zeros', 'micro_means', 'macro_means', 'dict_default_micro_means', 'dict_default_macro_means']\nlist_concerned_type_data = ['tr']\nlist_concerned_num_models = [num_models]\n\nn_steps=100\n\nlist_biomakers_file_loc = export_biomarker_file(list_concerned_type_baseline, list_concerned_type_data, list_concerned_num_models, biomarkers_folder, n_steps)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T11:03:29.003973Z","iopub.execute_input":"2024-07-04T11:03:29.004281Z","iopub.status.idle":"2024-07-04T12:16:43.615082Z","shell.execute_reply.started":"2024-07-04T11:03:29.004254Z","shell.execute_reply":"2024-07-04T12:16:43.614087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2.3. MOGONET(NO IG)","metadata":{}},{"cell_type":"code","source":"if Run_MOGONET:\n    biomarker_file_name = f'mogonet_full_top_biomarkers_sorted_desc_score_{num_models}models.csv'\n    main_biomarker_mogonet = f'/kaggle/input/{dataset_name}/main_biomarker.py'\n\n    start_time=datetime.now()\n    !python '{main_biomarker_mogonet}' '{data_folder}' '{model_folder}' '{dim_he_list}' '{view_list}' '{num_models}' '{postfix_tr}' '{postfix_te}' '{biomarkers_folder}' '{biomarker_file_name}' '{topn}'\n    print(f'\\t=>Result (Here print out the top {topn} biomakers with highest values):')\n    end_time=datetime.now()\n    print(f'\\tRun in {end_time-start_time}')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-04T12:16:43.616524Z","iopub.execute_input":"2024-07-04T12:16:43.616904Z","iopub.status.idle":"2024-07-04T12:16:43.623233Z","shell.execute_reply.started":"2024-07-04T12:16:43.616865Z","shell.execute_reply":"2024-07-04T12:16:43.622273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. PHASE 3","metadata":{}},{"cell_type":"code","source":"# Threshold to take number of genes (biomarkers) per subtype\n\nROOT_DATA_FOLDER = f'/kaggle/input/{dataset_name}/{COHORT}/train_test_split_org/'\nRANDOM_STATE = 42\n\nLIST_OMICS = ['GE', 'CNA']\nLIST_OMICS_ID = np.arange(1,len(LIST_OMICS)+1,1)\n\n# Single omic or Multi-omics| to run experiments\nLIST_EXP_OMICS = [\"GE_CNA\"]\n\n\nLIST_TYPE_DATA = ['train', 'test']\nDATA_FOLDER = {'train': ROOT_DATA_FOLDER,\n              'test': ROOT_DATA_FOLDER}\n\n\nORIGINAL_MAPPING_NAME = {  \n    0: 'Normal', \n    1: 'Basal', \n    2: 'Her2', \n    3: 'LumA',\n    4: 'LumB'\n} ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:02:46.224266Z","iopub.execute_input":"2024-07-04T16:02:46.224643Z","iopub.status.idle":"2024-07-04T16:02:46.230611Z","shell.execute_reply.started":"2024-07-04T16:02:46.224598Z","shell.execute_reply":"2024-07-04T16:02:46.229704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BIOMARKERS_RESULT_FOLDER = '/kaggle/working/biomarkers'\nlist_loc_biomarkers = []\nfor dirname, _, filenames in os.walk(BIOMARKERS_RESULT_FOLDER):\n    for filename in filenames:\n        list_loc_biomarkers.append(os.path.join(dirname, filename))\n# print(list_loc_biomarkers)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T12:16:43.641676Z","iopub.execute_input":"2024-07-04T12:16:43.642047Z","iopub.status.idle":"2024-07-04T12:16:43.650983Z","shell.execute_reply.started":"2024-07-04T12:16:43.641989Z","shell.execute_reply":"2024-07-04T12:16:43.650287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.1. Check overlap with other genes","metadata":{}},{"cell_type":"code","source":"# direct_evidence_gene_list = [\n#     \"EGFR\", \"MGMT\", \"CXCL8\", \"H2AX\", \"VEGFA\", \"EGF\", \"MMP2\", \"HIF1A\", \"MMP9\", \"IL1B\",\n#     \"MYC\", \"CDK6\", \"MTOR\", \"HES1\", \"FN1\", \"NDRG1\", \"CTSB\", \"PTK2\", \"CD9\", \"PROM1\",\n#     \"WT1\", \"FAT1\", \"HEY1\", \"DUSP6\", \"NCOR1\", \"NOTCH1\", \"BMI1\", \"BHLHE40\", \"TP53BP1\", \"PIM1\",\n#     \"MET\", \"JAG1\", \"CSTA\", \"CHI3L1\", \"APC\", \"CTSK\", \"NOTCH2\", \"FAM83D\", \"GSTT1\", \"FOSL2\",\n#     \"GDNF\", \"TES\", \"PRKN\", \"SUZ12\", \"CSTB\", \"ZBTB7A\", \"BCHE\", \"RUNX1\", \"CCNH\", \"LRRC59\",\n#     \"PML\", \"POLK\", \"SRRT\", \"RUNX3\", \"CTNND2\", \"TMEM135\", \"MDM4\", \"H3-3A\", \"BRD2\", \"TRMT11\",\n#     \"NF1\", \"HOXD10\", \"GRIK2\", \"JAG2\", \"BRD4\", \"LTBP4\", \"MACIR\", \"NOTCH3\", \"LZTR1\", \"H3C2\",\n#     \"SLC22A10\", \"DEUP1\", \"SEPTIN14\", \"TGM2\", \"TNFSF10\", \"IL2\", \"RECK\", \"IFNA2\"\n# ]\n# top40 + PAM50 \n\ndirect_evidence_gene_list = [\n    'ABCB1', 'ABCG2', 'AKT1', 'AR', 'ATM', 'BARD1', 'BCL2', 'BIRC5', 'BRCA2', 'BRIP1', 'CASP7', \n    'CASP8', 'CAT', 'CCND1', 'CDH1', 'CHEK2', 'CXCL8', 'CYP1A1', 'CYP3A4', 'DDIT3', 'EGFR', \n    'ERBB2', 'ESR1', 'GSTP1', 'HMMR', 'HMOX1', 'IFNG', 'IL1B', 'IL6', 'JUN', 'KRAS', 'MDM2', \n    'MKI67', 'MMP2', 'MMP9', 'MTOR', 'NFKBIA', 'NOS2', 'NQO2', 'PALB2', 'PARP1', 'PHB', 'PIK3CA', \n    'PPM1D', 'PTGS2', 'RAD51A', 'RAD54L', 'RB1', 'RB1CC1', 'RELA', 'SLC22A1L', 'SOD2', 'STAT3', \n    'TNF', 'TOP2A', 'TP53', 'TSG101', 'XRCC3']\ntopn_lst = [50, 100, 200, 400]","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:41:40.564170Z","iopub.execute_input":"2024-07-04T15:41:40.564538Z","iopub.status.idle":"2024-07-04T15:41:40.571856Z","shell.execute_reply.started":"2024-07-04T15:41:40.564509Z","shell.execute_reply":"2024-07-04T15:41:40.570756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BIOMARKERS_RESULT_FOLDER = '/kaggle/input/brca-deepssc/biomarkers'\nlist_loc_biomarkers = []\nfor dirname, _, filenames in os.walk(BIOMARKERS_RESULT_FOLDER):\n    for filename in filenames:\n        list_loc_biomarkers.append(os.path.join(dirname, filename))\n# print(list_loc_biomarkers)\nfor file_loc in list_loc_biomarkers:\n    file_name = file_loc.split('/')[-1]\n    ig_biomarkers = pd.read_csv(file_loc).iloc[:, 0].str.split(r'\\|').str[0].values.tolist()\n    baseline_name = '-'.join(file_name.split('_')[:-3])\n#     print(file_name)\n    print(baseline_name)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:47:23.790315Z","iopub.execute_input":"2024-07-04T15:47:23.790676Z","iopub.status.idle":"2024-07-04T15:47:23.856400Z","shell.execute_reply.started":"2024-07-04T15:47:23.790647Z","shell.execute_reply":"2024-07-04T15:47:23.855497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = []\n\nfor file_loc in list_loc_biomarkers:\n    file_name = file_loc.split('/')[-1]\n    ig_biomarkers = pd.read_csv(file_loc).iloc[:, 0].str.split(r'\\|').str[0].values.tolist()\n    baseline_name = '-'.join(file_name.split('_')[:-3])\n    for i in topn_lst:\n        intersect_direct = sorted(list(set(direct_evidence_gene_list).intersection(set(ig_biomarkers[:i]))))\n        intersect_direct_str = ', '.join(intersect_direct)\n        data.append([baseline_name, i, intersect_direct_str]) #, intersect_reference, intersect_inference])\nprint(data)\ndf = pd.DataFrame(data, columns=['Baseline', 'TopN', 'Intersect with Direct Evidence Gene List']) #, 'Intersect with Top Reference Gene List', 'Intersect with Top Inference Gene List'])\n\n# Print table\npd.set_option('display.max_colwidth', None)\ndisplay(df)\n\ndf.to_csv(\"/kaggle/working/genes_overlap.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:47:35.400641Z","iopub.execute_input":"2024-07-04T15:47:35.401034Z","iopub.status.idle":"2024-07-04T15:47:35.717323Z","shell.execute_reply.started":"2024-07-04T15:47:35.400998Z","shell.execute_reply":"2024-07-04T15:47:35.716561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.2. TEST WITH CLASSIC ML ALGO","metadata":{}},{"cell_type":"code","source":"# pd.set_option('display.max_columns', None)\n# pd.set_option('display.expand_frame_repr', False)\n# pd.set_option('max_colwidth', None)\ndef printmd(string, color=None):\n    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n    display(Markdown(colorstr))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:56:53.160269Z","iopub.execute_input":"2024-07-04T15:56:53.160653Z","iopub.status.idle":"2024-07-04T15:56:53.165400Z","shell.execute_reply.started":"2024-07-04T15:56:53.160609Z","shell.execute_reply":"2024-07-04T15:56:53.164361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tuning_and_eval(gridcvs, X_train, y_train, X_test, y_test,\n                    scoring, refit, is_binary_problem,\n                    result_on_dataset, rank_hparams_info):\n    assert 'test' in result_on_dataset\n    assert isinstance(rank_hparams_info, bool)\n    ###\n    lst_dct_result = [] # to return\n    ###\n\n    start=datetime.now()\n    X = {}\n    y = {}\n    X['train'] = X_train\n    X['test'] = X_test\n    y['train'] = y_train\n    y['test'] = y_test\n\n    for model_name, gs_est in sorted(gridcvs.items()):\n        ###\n        sub_result = {}\n        sub_result['model'] = model_name\n        ###\n\n        start_individual_type_model = datetime.now()\n        gs_est.fit(X['train'],y['train'])\n\n        ###\n        sub_result['best_params'] = gs_est.best_params_\n        ###\n\n        ###\n        sub_result[f'best_tuning_{refit}'] = gs_est.best_score_ * 100\n        sub_result['best_tuning_std'] = gs_est.cv_results_[f'std_test_{refit}'][gs_est.best_index_] * 100\n        ###\n\n        if rank_hparams_info:\n            select_result_cols = []\n            for metric in scoring:\n                select_result_cols.extend(['rank_test_'+metric,'mean_test_'+ metric, 'std_test_'+metric])\n            select_result_cols.extend(['params'])\n\n            dataframe_results = pd.DataFrame(gs_est.cv_results_).loc[:,select_result_cols].sort_values(by=f'mean_test_{refit}',ascending=False)\n            display(dataframe_results[:10])\n\n        for type_data in result_on_dataset:\n            y_predict = gs_est.predict(X[type_data])\n\n            acc = accuracy_score(y_true=y[type_data], y_pred=y_predict)\n\n            ###\n            sub_result[f'{type_data}_acc'] = acc * 100\n            ###\n\n            if is_binary_problem:\n                f1 = f1_score(y_true=y[type_data], y_pred=y_predict,average='binary')\n                y_score = gs_est.predict_proba(X[type_data])[:, 1]\n                roc_auc = roc_auc_score(y_true=y[type_data], y_score=y_score)\n\n                ###\n                sub_result[f'{type_data}_f1'] = f1 * 100\n                ###\n\n                ###\n                sub_result[f'{type_data}_roc_auc'] = roc_auc * 100\n                ###\n            else:\n                f1_macro = f1_score(y_true=y[type_data], y_pred=y_predict,average='macro')\n                f1_weighted = f1_score(y_true=y[type_data], y_pred=y_predict,average='weighted')\n\n                ###\n                sub_result[f'{type_data}_f1_macro'] = f1_macro * 100\n                ###\n\n                ###\n                sub_result[f'{type_data}_f1_weighted'] = f1_weighted * 100\n                ##\n\n            ###\n            lst_dct_result.append(sub_result)\n            ###\n\n            pd_cfm = pd.crosstab(\n                y[type_data]\n                , y_predict\n                , margins=True\n                , rownames=['True label']\n                , colnames=['Pred label']\n            )\n            pd_cfm.index = list(ORIGINAL_MAPPING_NAME.values()) + ['All']\n            pd_cfm.columns = list(ORIGINAL_MAPPING_NAME.values()) + ['All']\n\n            folder_save_fig = f\"/kaggle/working/cfm/{biomarker_file.split('/')[-1].split('.')[-2]}/{model_name}\"\n            if not os.path.exists(folder_save_fig):\n                os.makedirs(folder_save_fig)\n            path_save_fig = f\"{folder_save_fig}/top{threshold}.png\"\n            display_classification_report(n_class=len(ORIGINAL_MAPPING_NAME)\n                                          , label=y[type_data]\n                                          , pred= y_predict\n                                          , label_mapping_name=ORIGINAL_MAPPING_NAME.values()\n                                          , path=path_save_fig\n                                          , shown=False\n                                         )\n    return lst_dct_result","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:56:58.621907Z","iopub.execute_input":"2024-07-04T15:56:58.622252Z","iopub.status.idle":"2024-07-04T15:56:58.640884Z","shell.execute_reply.started":"2024-07-04T15:56:58.622224Z","shell.execute_reply":"2024-07-04T15:56:58.639955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RANDOM_STATE = 42\ndef validate_biomarker(dict_X_train, dict_y_train, dict_X_test, dict_y_test,\n                       omics=['GE_CNA', 'GE','CNA'], random_state = RANDOM_STATE,\n                       result_on_dataset = ['train','test'], rank_hparams_info = True,\n                       is_binary_problem=False):\n    assert 'test' in result_on_dataset\n    assert isinstance(rank_hparams_info, bool)\n    ###\n    validate_biomarker_result = []\n    ###\n    scoring = None\n    refit= None\n    if is_binary_problem:\n        scoring = ['f1','accuracy','roc_auc']\n        refit = 'f1'\n    else: \n        scoring = ['f1_macro','f1_weighted', 'accuracy']\n        refit = 'f1_macro'\n\n    # Initializing classifiers\n    clf1 = LogisticRegression(random_state=random_state, max_iter=10000, n_jobs=-1)\n\n    # Binary case, probability = True to cal ROC_AUC, slowdown k-fold....\n    clf2 = SVC(random_state=random_state, probability=is_binary_problem)\n\n    clf3 = RandomForestClassifier(random_state=random_state,n_jobs=-1)\n\n    # Building the pipelines\n    pipe1 = Pipeline([('std', 'passthrough'),\n                      ('clf1', clf1)])\n\n    pipe2 = Pipeline([('std', 'passthrough'),\n                      ('clf2', clf2)])\n\n#     # only apply std to mRNA data/ BY index mRNA| ignore or passthorough not to\n#     # apply standard scaler to remaining index corresponding to CNA data\n#     column_trans = ColumnTransformer(\n#         [('scaler', StandardScaler(),list(range(len(GENE['mRNA']))))]\n#         ,remainder='passthrough')\n    # Setting up the parameter grids\n    param_grid1 = [{\n                    'std': [MinMaxScaler()],\n                    'clf1__penalty': ['l2'],\n                    'clf1__multi_class':[\"multinomial\"],\n                    'clf1__solver':[\"newton-cg\"],\n                    'clf1__class_weight': [\"balanced\"],\n                    'clf1__C': np.power(10., np.arange(-4, 3)),\n                    }]\n\n    param_grid2 = [{\n                    'std': [MinMaxScaler()],\n                    'clf2__kernel': ['rbf'],\n                    'clf2__class_weight': [\"balanced\"],\n                    'clf2__C': np.power(10., np.arange(-4, 3)),\n                    'clf2__gamma': list(np.power(10., np.arange(-4, 0))) + ['scale']\n                    }]\n\n#     param_grid3 = [{'n_estimators': [50, 100, 150],\n#                     'max_features': [\"sqrt\"],\n#                     'max_depth' : list(range(1, 10)) + [None],\n#                     'criterion' :[\"gini\"],\n#                     'class_weight': [\"balanced\", \"balanced_subsample\"]}]\n\n    # Setting up multiple GridSearchCV objects, 1 for each algorithm\n    gridcvs = {}\n#     cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=10, random_state=random_state)\n    cv = RepeatedStratifiedKFold(n_splits=4, n_repeats=5, random_state=random_state)\n\n    train_options = zip(\n                        (param_grid1\n                         ,param_grid2\\\n#                          ,param_grid3\n                        ),\n                        (pipe1,pipe2\\\n                         ,clf3\n                        ),\n                        ('1_Softmax', '2_SVM'\\\n#                          ,'3_RandomForest'\n                        )\n                       )\n\n    for pgrid, est, model_name in train_options:\n        gcv = GridSearchCV(estimator=est,\n                           param_grid=pgrid,\n                           scoring=scoring,\n                           n_jobs=-1,\n                           cv=cv,\n                           verbose=0,\n                           refit=refit)\n        gridcvs[model_name] = gcv\n\n    for omic in omics:\n#         print('-'*100)\n#         printmd(f'Validate on {omic} data:\\n', color=\"red\")\n\n        X_train = dict_X_train[omic]\n        y_train = np.array(dict_y_train[omic], dtype=np.int16)\n#         print('Train dist: ', np.unique(y_train, return_counts=True ))\n\n        X_test = dict_X_test[omic]\n        y_test = np.array(dict_y_test[omic], dtype=np.int16)\n#         print('Test dist', np.unique(y_test, return_counts=True ),'\\n')\n\n        # run tuning and eval\n        tmp_lst_dct_tuning_result = tuning_and_eval(gridcvs, X_train, y_train, X_test, y_test,\\\n                        scoring, refit,is_binary_problem,\n                        result_on_dataset, rank_hparams_info)\n        ###\n        tmp_base= {'using_omic': omic}\n        validate_biomarker_result.extend([copy.deepcopy(tmp_base) for i in range(len(tmp_lst_dct_tuning_result))])\n        for dct_tmp, dct_val in zip(tmp_lst_dct_tuning_result, validate_biomarker_result):\n            dct_val.update(dct_tmp)\n        ###\n    return validate_biomarker_result","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:27:02.286286Z","iopub.execute_input":"2024-07-04T16:27:02.286680Z","iopub.status.idle":"2024-07-04T16:27:02.305814Z","shell.execute_reply.started":"2024-07-04T16:27:02.286641Z","shell.execute_reply":"2024-07-04T16:27:02.304785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(biomarker_file, threshold):\n    # init var and para to save the result\n    ###\n    validate_result=[]\n    base_result = {}\n    ###\n#     dct_data_structure = {col: [] for col in lst_cols}\n#     pd_result = pd.DataFrame(columns=lst_cols)\n\n    # Read data\n    dict_df_label = {}\n    dict_df_data = {}\n    # Read data as df and create numpy array data for labeled data\n    for type_data in LIST_TYPE_DATA:\n        # modified\n        dict_df_label[type_data] = pd.read_csv(DATA_FOLDER[type_data] + f'labels_{type_data[:2]}.csv', names=['disease_subtypes'])\n        # ---------------------------------\n\n        # added\n        dict_df_label[type_data]['disease_subtypes'] = dict_df_label[type_data]['disease_subtypes'].astype('int')\n        dict_df_label[type_data].index.names = ['sampleID']\n        \n        dict_df_label[type_data].replace({'disease_subtypes': ORIGINAL_MAPPING_NAME}, inplace=True)\n        # ---------------------------------\n        \n        \n        dict_df_omics = {}\n        dict_narray_omics = {}\n        for omic in LIST_OMICS:\n            # added\n            tmp_feat_name = pd.read_csv(DATA_FOLDER[type_data]+ f'{LIST_OMICS.index(omic)+1}_featname.csv', names=['feat_name'])\n#             tmp_feat_name['feat_name'] = tmp_feat_name['feat_name'].str.split('|').str[0]\n            lst_name = tmp_feat_name.values.reshape(-1).tolist()\n            # ---------------------------------\n\n            # modified\n            dict_df_omics[omic] = pd.read_csv(DATA_FOLDER[type_data] + f'{LIST_OMICS.index(omic)+1}_{type_data[:2]}.csv',names=lst_name)\n            # ---------------------------------\n\n        dict_df_data[type_data] = dict_df_omics\n\n    LABEL_MAPPING_NAME = dict_df_label['train']['disease_subtypes'].astype('category').cat.categories # sorted by alphabetical order\n#     print('LABEL_MAPPING_NAME', LABEL_MAPPING_NAME)\n    print(\"LENGTH OF LABEL_MAPPING_NAME\", len(LABEL_MAPPING_NAME))\n    \n    # Convert categorical label to numerical label\n    for type_data in LIST_TYPE_DATA:\n        dict_df_label[type_data].loc[:,'disease_subtypes'] = dict_df_label[type_data]['disease_subtypes'].astype('category').cat.codes\n\n    #---------------------------------------------------------------------------------------\n    # Keep only biomarker genes found from TCGA data\n#     print('-'*100)\n#     print('KEEP ONLY BIOMARKER GENES FOUND FROM TCGA DATA')\n    score_genes = pd.read_csv(biomarker_file)\n    score_genes = score_genes.iloc[:threshold, 0]\n    top_genes = list(set(score_genes.to_numpy(copy=True).reshape(-1)))\n#     print(top_genes)\n    top_genes = [gene.upper() for gene in top_genes]\n#     print(f'Top {threshold} from TCGA have {len(top_genes)} unique genes/features:')\n    ###\n    base_result['n_unq_markers'] = len(top_genes)\n    base_result['lst_unq_markers'] = top_genes\n    ###\n    \n    GENE = {}\n    for omic in LIST_OMICS:\n        GENE[omic] = dict_df_data['train'][omic].columns[\n#             dict_df_data['train'][omic].columns.str.upper().str.split(r'\\|').str[0].isin(top_genes)\n            dict_df_data['train'][omic].columns.str.upper().isin(top_genes)\n        ].to_numpy(copy=True).tolist()\n\n#         print(f'\\twith {omic} TOP {threshold}:', len(GENE[omic]))\n        ###\n        base_result[f'n_unq_{omic}'] = len(GENE[omic])\n        base_result[f'lst_unq_{omic}'] = GENE[omic]\n        ###\n    # NOTE THAT DNAmythyl and mRNA maybe have same genename in top gene => incresing num features comparing to num unique genes\n\n        for type_data in LIST_TYPE_DATA:\n            dict_df_data[type_data][omic] = dict_df_data[type_data][omic][GENE[omic]].copy(deep=True)\n    \n    dict_X = {}\n    dict_y = {}\n    for type_data in LIST_TYPE_DATA:\n        dict_X[type_data] = {}\n        dict_y[type_data] = {}\n\n    for type_omic in LIST_EXP_OMICS:\n        if '_' in type_omic:\n#             print(f'Creating data for multi-omics experiment: {type_omic}')\n            list_omics = type_omic.split('_')\n            for type_data in LIST_TYPE_DATA:\n                tuple_data_omics = tuple([dict_df_data[type_data][single_omic] for single_omic in list_omics])\n                dict_X[type_data][type_omic] = np.concatenate(tuple_data_omics, axis=1)\n        else:\n#             print(f'Creating data for single omic experiment: {type_omic}')\n            for type_data in LIST_TYPE_DATA:\n                dict_X[type_data][type_omic] = dict_df_data[type_data][type_omic].to_numpy(copy=True)\n\n        for type_data in LIST_TYPE_DATA:\n            dict_y[type_data][type_omic] = dict_df_label[type_data]['disease_subtypes'].to_numpy(copy=True)\n\n\n    #---------------------------------------------------------------------------------------\n    tmp_lst_dct_validate_biomarker_result = validate_biomarker(dict_X['train'], dict_y['train'], dict_X['test'], dict_y['test'],\n                       omics=LIST_EXP_OMICS, random_state=RANDOM_STATE,\n                       result_on_dataset= ['test'], rank_hparams_info =False,\n                       is_binary_problem = (len(LABEL_MAPPING_NAME)==2))\n    validate_result.extend([copy.deepcopy(base_result) for i in range(len(tmp_lst_dct_validate_biomarker_result))])\n    for dct_tmp, dct_val in zip(tmp_lst_dct_validate_biomarker_result, validate_result):\n        dct_val.update(dct_tmp)\n    return validate_result","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:24:54.348001Z","iopub.execute_input":"2024-07-04T16:24:54.348404Z","iopub.status.idle":"2024-07-04T16:24:54.371473Z","shell.execute_reply.started":"2024-07-04T16:24:54.348373Z","shell.execute_reply":"2024-07-04T16:24:54.370466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# excluded_files = ['mogonet_full_top_biomarkers_sorted_desc_score_5models.csv']\n# excluded_files = [f'{BIOMARKERS_RESULT_FOLDER}/{COHORT}/'+biomarker_file for biomarker_file in excluded_files]\n\nexcluded_files = [] # evaluation all candidate biomarkers result","metadata":{"execution":{"iopub.status.busy":"2024-07-04T15:58:42.339507Z","iopub.execute_input":"2024-07-04T15:58:42.339873Z","iopub.status.idle":"2024-07-04T15:58:42.343860Z","shell.execute_reply.started":"2024-07-04T15:58:42.339842Z","shell.execute_reply":"2024-07-04T15:58:42.342728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.__version__)\nprint(sklearn.__version__)\nprint(np.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T12:16:43.824315Z","iopub.execute_input":"2024-07-04T12:16:43.824576Z","iopub.status.idle":"2024-07-04T12:16:43.834513Z","shell.execute_reply.started":"2024-07-04T12:16:43.824550Z","shell.execute_reply":"2024-07-04T12:16:43.833707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n\nimport copy\nfrom sklearn.compose import ColumnTransformer \nfrom IPython.display import Markdown\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\nfrom scipy.stats import mode\nfrom datetime import datetime\n\n!pip install captum --quiet\nfrom captum.attr import IntegratedGradients\n\ndef printmd(string, color=None):\n    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n    display(Markdown(colorstr))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:00:21.470113Z","iopub.execute_input":"2024-07-04T16:00:21.470471Z","iopub.status.idle":"2024-07-04T16:00:29.036925Z","shell.execute_reply.started":"2024-07-04T16:00:21.470441Z","shell.execute_reply":"2024-07-04T16:00:29.035869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Ignore ConvergenceWarning\n# warnings.filterwarnings(\"ignore\", category = ConvergenceWarning)\n\n##\nresult = []\nTHRESHOLD_LST = [20, 50, 90, 117, 150, 200, 250, 300, 350, 400]\n##\n\nfor biomarker_file in list_loc_biomarkers:\n    if biomarker_file in excluded_files:\n        continue\n#     print(\"*\"*100)\n    baseline = biomarker_file.split('/')[-1].split('.')[-2]\n    printmd(baseline,'green')\n#         print(biomarker_file)\n\n    start = datetime.now()\n    for threshold in THRESHOLD_LST:\n        ###\n        tmp_result = []\n        base_init_dct_result = {'top': threshold, 'baseline': baseline}\n        tmp_validate_result = validate(biomarker_file,threshold)\n        tmp_result.extend([copy.deepcopy(base_init_dct_result) for i in range(len(tmp_validate_result))])\n        for dct_tmp, dct_val in zip(tmp_validate_result, tmp_result):\n            dct_val.update(dct_tmp)\n\n        result.extend(tmp_result)\n        \n    print(f'Total Time: {datetime.now()-start}')\n        ###\n#         print(f\"Top {threshold} - Using {tmp_result[0]['n_unq_markers']} uniques biomarkers in totals\")\n#         print(tmp_result[0]['lst_unq_markers'])\n#         print('\\n'*2)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:27:11.075919Z","iopub.execute_input":"2024-07-04T16:27:11.076263Z","iopub.status.idle":"2024-07-04T16:50:26.419427Z","shell.execute_reply.started":"2024-07-04T16:27:11.076235Z","shell.execute_reply":"2024-07-04T16:50:26.418339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3.3. Compare all IG baselines and MOGONET","metadata":{}},{"cell_type":"code","source":"avg_acc_all_models = {}\navg_f1_all_models = {}\nfiltered_results = []\n\nfor res in result:\n#         print(res)\n    model_type = res['model']\n    baseline_type = \"-\".join(res['baseline'].split('_')[:-3])\n    top_n = res['top']\n    accuracy_t = res['test_acc']\n    f1_score_t = res.get('test_f1_macro', res.get('test_f1', 0))\n\n    filtered_results.append({\n        'model_type': model_type,\n        'baseline_type': baseline_type,\n        'top_n': top_n,\n        'accuracy_t': accuracy_t,\n        'f1_score_t': f1_score_t\n    })\n    \n    if model_type not in avg_acc_all_models:\n        avg_acc_all_models[model_type] = {}\n        avg_f1_all_models[model_type] = {}\n\n    if baseline_type not in avg_acc_all_models[model_type]:\n        avg_acc_all_models[model_type][baseline_type] = []\n        avg_f1_all_models[model_type][baseline_type] = []\n\n    avg_acc_all_models[model_type][baseline_type].append((top_n, accuracy_t))\n    avg_f1_all_models[model_type][baseline_type].append((top_n, f1_score_t))\n        \nfor model_type in avg_acc_all_models:\n    for baseline_type in avg_acc_all_models[model_type]:\n        avg_acc_all_models[model_type][baseline_type].sort(key=lambda x: x[0])\n        avg_f1_all_models[model_type][baseline_type].sort(key=lambda x: x[0])","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:51:41.964364Z","iopub.execute_input":"2024-07-04T16:51:41.964781Z","iopub.status.idle":"2024-07-04T16:51:41.975846Z","shell.execute_reply.started":"2024-07-04T16:51:41.964744Z","shell.execute_reply":"2024-07-04T16:51:41.974852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(metrics, metric_name):\n    folder_save_fig = f\"/kaggle/working/cmp\"\n    if not os.path.exists(folder_save_fig):\n        os.makedirs(folder_save_fig)\n    path_save_fig = f'{folder_save_fig}/{metric_name}.png'\n    plt.figure(figsize = (8,4), dpi=300)\n    for baseline_name, values in metrics.items():\n        top_n_list = [item[0] for item in values]\n        metric_values = [item[1] for item in values]\n        plt.plot(top_n_list, metric_values, marker='o', label=baseline_name)\n    plt.title(f'{metric_name} for different baselines and top N features')\n    plt.xlabel('Top N features')\n    plt.ylabel(metric_name)\n    plt.legend(fontsize='small', bbox_to_anchor=(1.05, 1), loc='upper left')    \n    plt.xticks(top_n_list)\n    plt.yticks(list(range(35, 91, 5)))\n    plt.grid(axis='y')\n    plt.tight_layout()\n    plt.savefig(path_save_fig, facecolor='white', edgecolor='white')\n    plt.show()\n    \n# Plot accuracy\nfor model_type in avg_acc_all_models.keys():\n    print('*' * 40, model_type, '*' * 40)\n    plot_metrics(avg_acc_all_models[model_type], f'Accuracy for {model_type}')\n    plot_metrics(avg_f1_all_models[model_type], f'F1 Score for {model_type}')\n    print('\\n\\n')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:51:48.486063Z","iopub.execute_input":"2024-07-04T16:51:48.486429Z","iopub.status.idle":"2024-07-04T16:51:51.980082Z","shell.execute_reply.started":"2024-07-04T16:51:48.486399Z","shell.execute_reply":"2024-07-04T16:51:51.979049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convenient for modifying plot\njson_file = \"/kaggle/working/results.json\"\n\nwith open(json_file, mode='w', encoding='utf-8') as file:\n    json.dump(filtered_results, file, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T16:52:01.645795Z","iopub.execute_input":"2024-07-04T16:52:01.646250Z","iopub.status.idle":"2024-07-04T16:52:01.654304Z","shell.execute_reply.started":"2024-07-04T16:52:01.646211Z","shell.execute_reply":"2024-07-04T16:52:01.653300Z"},"trusted":true},"execution_count":null,"outputs":[]}]}